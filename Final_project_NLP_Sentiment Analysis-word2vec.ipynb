{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "from gensim.models import word2vec\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/camillebustalinio/Desktop/Camille/term 2 project/airbnb data/final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_data = data[(data.language=='en')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Import the stop word list\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "# Use regular expressions to do a find-and-replace\n",
    "def preprocessing(x): # x = reviews\n",
    "    x = str(x)\n",
    "    #x = x.decode(\"utf8\")\n",
    "    raw_sentences = tokenizer.tokenize(x.strip())\n",
    "    raw_sentences_list =  [[item] for item in raw_sentences]\n",
    "    \n",
    "    def sentence_to_word(sentence_list):\n",
    "        try:\n",
    "            x = re.sub(\"[^a-zA-Z]\", \" \", sentence_list)\n",
    "            x = x.lower().split()\n",
    "            return x\n",
    "        except:\n",
    "            #if x == float:\n",
    "            return \" \"\n",
    "    sentence_list = [sentence_to_word(sentence) for sentence in raw_sentences]\n",
    "    \n",
    "    return sentence_list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=eng_data.comments[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The place was clean and spacious and the guy there was pretty nice and helpful. Only thing was that the old lady charged me $25 for keeping my luggage for 5 hours.  '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The place was clean and spacious and the guy there was pretty nice and helpful.'],\n",
       " ['Only thing was that the old lady charged me $25 for keeping my luggage for 5 hours.']]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_sentences_list =  [[item] for item in raw_sentences]\n",
    "raw_sentences_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_to_word(sentence_list):\n",
    "        try:\n",
    "            x = re.sub(\"[^a-zA-Z]\", \" \", sentence_list)\n",
    "            x = x.lower().split()\n",
    "            return x\n",
    "        except:\n",
    "            #if x == float:\n",
    "            return \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the',\n",
       "  'place',\n",
       "  'was',\n",
       "  'clean',\n",
       "  'and',\n",
       "  'spacious',\n",
       "  'and',\n",
       "  'the',\n",
       "  'guy',\n",
       "  'there',\n",
       "  'was',\n",
       "  'pretty',\n",
       "  'nice',\n",
       "  'and',\n",
       "  'helpful'],\n",
       " ['only',\n",
       "  'thing',\n",
       "  'was',\n",
       "  'that',\n",
       "  'the',\n",
       "  'old',\n",
       "  'lady',\n",
       "  'charged',\n",
       "  'me',\n",
       "  'for',\n",
       "  'keeping',\n",
       "  'my',\n",
       "  'luggage',\n",
       "  'for',\n",
       "  'hours']]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sentence_to_word(sentence) for sentence in raw_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the',\n",
       "  'place',\n",
       "  'was',\n",
       "  'clean',\n",
       "  'and',\n",
       "  'spacious',\n",
       "  'and',\n",
       "  'the',\n",
       "  'guy',\n",
       "  'there',\n",
       "  'was',\n",
       "  'pretty',\n",
       "  'nice',\n",
       "  'and',\n",
       "  'helpful'],\n",
       " ['only',\n",
       "  'thing',\n",
       "  'was',\n",
       "  'that',\n",
       "  'the',\n",
       "  'old',\n",
       "  'lady',\n",
       "  'charged',\n",
       "  'me',\n",
       "  'for',\n",
       "  'keeping',\n",
       "  'my',\n",
       "  'luggage',\n",
       "  'for',\n",
       "  'hours']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2vec_list = [preprocessing(comment) for comment in eng_data.comments]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the',\n",
       "  'place',\n",
       "  'was',\n",
       "  'clean',\n",
       "  'and',\n",
       "  'spacious',\n",
       "  'and',\n",
       "  'the',\n",
       "  'guy',\n",
       "  'there',\n",
       "  'was',\n",
       "  'pretty',\n",
       "  'nice',\n",
       "  'and',\n",
       "  'helpful'],\n",
       " ['only',\n",
       "  'thing',\n",
       "  'was',\n",
       "  'that',\n",
       "  'the',\n",
       "  'old',\n",
       "  'lady',\n",
       "  'charged',\n",
       "  'me',\n",
       "  'for',\n",
       "  'keeping',\n",
       "  'my',\n",
       "  'luggage',\n",
       "  'for',\n",
       "  'hours']]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id_x</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>id_y</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>...</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>language</th>\n",
       "      <th>price_tag</th>\n",
       "      <th>word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8308113</td>\n",
       "      <td>47419975</td>\n",
       "      <td>2015-09-18</td>\n",
       "      <td>6288054</td>\n",
       "      <td>Colin</td>\n",
       "      <td>Host was excellent and was contactable / respo...</td>\n",
       "      <td>8308113</td>\n",
       "      <td>Luxury Elegant Lrg Studio PacHeight</td>\n",
       "      <td>8739745</td>\n",
       "      <td>...</td>\n",
       "      <td>350</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-09-18</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[[host, was, excellent, and, was, contactable,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3320213</td>\n",
       "      <td>14805088</td>\n",
       "      <td>2014-06-26</td>\n",
       "      <td>17101713</td>\n",
       "      <td>Faye</td>\n",
       "      <td>The place was clean and spacious and the guy t...</td>\n",
       "      <td>3320213</td>\n",
       "      <td>Private Room with TWO Double Beds.</td>\n",
       "      <td>3553372</td>\n",
       "      <td>...</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2015-10-11</td>\n",
       "      <td>1.18</td>\n",
       "      <td>11</td>\n",
       "      <td>365</td>\n",
       "      <td>en</td>\n",
       "      <td>exp</td>\n",
       "      <td>[[the, place, was, clean, and, spacious, and, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3320213</td>\n",
       "      <td>17192435</td>\n",
       "      <td>2014-08-08</td>\n",
       "      <td>182792</td>\n",
       "      <td>Jocelyne &amp; Pontus</td>\n",
       "      <td>This place wasn't as pleasant as we hoped. Had...</td>\n",
       "      <td>3320213</td>\n",
       "      <td>Private Room with TWO Double Beds.</td>\n",
       "      <td>3553372</td>\n",
       "      <td>...</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2015-10-11</td>\n",
       "      <td>1.18</td>\n",
       "      <td>11</td>\n",
       "      <td>365</td>\n",
       "      <td>en</td>\n",
       "      <td>exp</td>\n",
       "      <td>[[this, place, wasn, t, as, pleasant, as, we, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3320213</td>\n",
       "      <td>18293826</td>\n",
       "      <td>2014-08-24</td>\n",
       "      <td>1104165</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>Nice room, cool neighbourhood. Note that this ...</td>\n",
       "      <td>3320213</td>\n",
       "      <td>Private Room with TWO Double Beds.</td>\n",
       "      <td>3553372</td>\n",
       "      <td>...</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2015-10-11</td>\n",
       "      <td>1.18</td>\n",
       "      <td>11</td>\n",
       "      <td>365</td>\n",
       "      <td>en</td>\n",
       "      <td>exp</td>\n",
       "      <td>[[nice, room, cool, neighbourhood], [note, tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3320213</td>\n",
       "      <td>18602107</td>\n",
       "      <td>2014-08-28</td>\n",
       "      <td>20421291</td>\n",
       "      <td>Dervla</td>\n",
       "      <td>The listing was accurate and the location was ...</td>\n",
       "      <td>3320213</td>\n",
       "      <td>Private Room with TWO Double Beds.</td>\n",
       "      <td>3553372</td>\n",
       "      <td>...</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2015-10-11</td>\n",
       "      <td>1.18</td>\n",
       "      <td>11</td>\n",
       "      <td>365</td>\n",
       "      <td>en</td>\n",
       "      <td>exp</td>\n",
       "      <td>[[the, listing, was, accurate, and, the, locat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  listing_id      id_x        date  reviewer_id  \\\n",
       "0           0     8308113  47419975  2015-09-18      6288054   \n",
       "1           1     3320213  14805088  2014-06-26     17101713   \n",
       "2           2     3320213  17192435  2014-08-08       182792   \n",
       "4           4     3320213  18293826  2014-08-24      1104165   \n",
       "5           5     3320213  18602107  2014-08-28     20421291   \n",
       "\n",
       "       reviewer_name                                           comments  \\\n",
       "0              Colin  Host was excellent and was contactable / respo...   \n",
       "1               Faye  The place was clean and spacious and the guy t...   \n",
       "2  Jocelyne & Pontus  This place wasn't as pleasant as we hoped. Had...   \n",
       "4             Daniel  Nice room, cool neighbourhood. Note that this ...   \n",
       "5             Dervla  The listing was accurate and the location was ...   \n",
       "\n",
       "      id_y                                 name  host_id  \\\n",
       "0  8308113  Luxury Elegant Lrg Studio PacHeight  8739745   \n",
       "1  3320213   Private Room with TWO Double Beds.  3553372   \n",
       "2  3320213   Private Room with TWO Double Beds.  3553372   \n",
       "4  3320213   Private Room with TWO Double Beds.  3553372   \n",
       "5  3320213   Private Room with TWO Double Beds.  3553372   \n",
       "\n",
       "                         ...                         price  minimum_nights  \\\n",
       "0                        ...                           350               1   \n",
       "1                        ...                           199               1   \n",
       "2                        ...                           199               1   \n",
       "4                        ...                           199               1   \n",
       "5                        ...                           199               1   \n",
       "\n",
       "  number_of_reviews  last_review  reviews_per_month  \\\n",
       "0                 1   2015-09-18               0.10   \n",
       "1                29   2015-10-11               1.18   \n",
       "2                29   2015-10-11               1.18   \n",
       "4                29   2015-10-11               1.18   \n",
       "5                29   2015-10-11               1.18   \n",
       "\n",
       "  calculated_host_listings_count  availability_365  language  price_tag  \\\n",
       "0                              1                 0        en    neutral   \n",
       "1                             11               365        en        exp   \n",
       "2                             11               365        en        exp   \n",
       "4                             11               365        en        exp   \n",
       "5                             11               365        en        exp   \n",
       "\n",
       "                                            word2vec  \n",
       "0  [[host, was, excellent, and, was, contactable,...  \n",
       "1  [[the, place, was, clean, and, spacious, and, ...  \n",
       "2  [[this, place, wasn, t, as, pleasant, as, we, ...  \n",
       "4  [[nice, room, cool, neighbourhood], [note, tha...  \n",
       "5  [[the, listing, was, accurate, and, the, locat...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "eng_data['word2vec'] = word2vec_list\n",
    "eng_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9240, 42928, 52168)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_eng_data = eng_data[(eng_data.price_tag=='exp')]\n",
    "cheap_eng_data = eng_data[(eng_data.price_tag=='cheap')]\n",
    "len(exp_eng_data), len(cheap_eng_data),len(exp_eng_data)+len(cheap_eng_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=eng_data.word2vec\n",
    "y=eng_data.price_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences_list = []\n",
    "for sentences in X:\n",
    "    sentences_list += [sentence for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['would', 'definitely', 'recommend', 'this', 'location']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.5/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin w2v\n",
      "w2v model :)\n"
     ]
    }
   ],
   "source": [
    "num_features = 50\n",
    "min_word_count = 40 \n",
    "num_workers = 4       \n",
    "context = 5          \n",
    "downsampling = 1e-3 \n",
    "\n",
    "print('begin w2v')\n",
    "# Initialize and train the model (this will take some time)\n",
    "\n",
    "\n",
    "model = word2vec.Word2Vec(sentences_list, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "print('w2v model :)')\n",
    "\n",
    "# save the model for later use\n",
    "model_name = \"airbnb_word2vec\"\n",
    "model.save(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'girl'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.doesnt_match(\"king queen girl crown\".split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pricey', 0.7832764983177185),\n",
       " ('overpriced', 0.7489678859710693),\n",
       " ('prices', 0.7069512605667114),\n",
       " ('unusual', 0.6785041689872742),\n",
       " ('crowded', 0.6601059436798096),\n",
       " ('reasonable', 0.6468909978866577),\n",
       " ('challenging', 0.6389502882957458),\n",
       " ('alternative', 0.6361240744590759),\n",
       " ('paying', 0.6230862736701965),\n",
       " ('rare', 0.6160271167755127)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"expensive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inexpensive', 0.7085990905761719),\n",
       " ('cabs', 0.6705433130264282),\n",
       " ('reasonable', 0.660757303237915),\n",
       " ('lyft', 0.6361374258995056),\n",
       " ('central', 0.6324213147163391),\n",
       " ('uberpool', 0.6147738695144653),\n",
       " ('taxis', 0.6041051745414734),\n",
       " ('convenient', 0.5901927351951599),\n",
       " ('affordable', 0.5866581201553345),\n",
       " ('downtown', 0.5842646956443787)]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"cheap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12127654,  0.08784179,  0.18817513,  0.17766376,  0.18350889,\n",
       "       -0.06299261, -0.04999506,  0.11631627,  0.16725485, -0.04495953,\n",
       "       -0.16157889, -0.03212997, -0.04244867, -0.08226436,  0.10065619,\n",
       "        0.11771405, -0.06446877,  0.15136918,  0.01015914, -0.007449  ,\n",
       "        0.29764175,  0.04519204,  0.13532314,  0.04683873, -0.17327774,\n",
       "        0.05752533,  0.00405649,  0.08557403,  0.10775098, -0.27687329,\n",
       "       -0.01155883, -0.13926803,  0.07233366, -0.25653321, -0.10377131,\n",
       "        0.1493576 , -0.25137556,  0.2694765 , -0.21393067,  0.06235608,\n",
       "        0.0869219 , -0.00464305, -0.03658104, -0.2792488 , -0.13039424,\n",
       "        0.03638535, -0.19918096,  0.09410358,  0.17771636, -0.07405628], dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['awesome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    nwords = 0.\n",
    "\n",
    "    # Convert it to a set, for speed \n",
    "    index2word_set = set(model.index2word)\n",
    "\n",
    "    # Loop over each word in the review and, if it is in the model's vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "\n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n",
    "\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    # Given a set of reviews (each one a list of words), calculate the average feature vector for each one and return a 2D numpy array \n",
    "\n",
    "    # Initialize a counter\n",
    "    counter = 0.\n",
    "\n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "\n",
    "    # Loop through the reviews\n",
    "    for review in reviews:\n",
    "        # Print a status message every 1000th review\n",
    "        if counter%1000. == 0.:\n",
    "            print(\"Review %d of %d\" % (counter, len(reviews)))\n",
    "\n",
    "        # Call the function (defined above) that makes average feature vectors\n",
    "        reviewFeatureVecs[counter] = makeFeatureVec(review, model, \\\n",
    "           num_features)\n",
    "\n",
    "        # Increment the counter\n",
    "        counter = counter + 1.\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def review_to_wordlist(x, remove_stopwords=True):\n",
    "    word_list = []\n",
    "    for sentence in x:\n",
    "        for word in sentence:\n",
    "            word_list.append(word)\n",
    "    \n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        word_list = [wordnet_lemmatizer.lemmatize(word) for word in word_list if word not in stops]\n",
    "    return word_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['host',\n",
       " 'excellent',\n",
       " 'contactable',\n",
       " 'responsive',\n",
       " 'time',\n",
       " 'would',\n",
       " 'definitely',\n",
       " 'recommend',\n",
       " 'location']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_to_wordlist(X[0])\n",
    "#print(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['listing',\n",
       "  'accurate',\n",
       "  'location',\n",
       "  'good',\n",
       "  'slight',\n",
       "  'smell',\n",
       "  'curry',\n",
       "  'hallway',\n",
       "  'never',\n",
       "  'room',\n",
       "  'never',\n",
       "  'bothered',\n",
       "  'u',\n",
       "  'much',\n",
       "  'also',\n",
       "  'hot',\n",
       "  'night',\n",
       "  'left',\n",
       "  'window',\n",
       "  'open',\n",
       "  'heard',\n",
       "  'lot',\n",
       "  'noise',\n",
       "  'manageable',\n",
       "  'check',\n",
       "  'quick',\n",
       "  'easy',\n",
       "  'maybe',\n",
       "  'little',\n",
       "  'abrupt',\n",
       "  'everything',\n",
       "  'needed',\n",
       "  'achieved',\n",
       "  'wifi',\n",
       "  'password',\n",
       "  'readily',\n",
       "  'available',\n",
       "  'signal',\n",
       "  'strong',\n",
       "  'thought',\n",
       "  'pricing',\n",
       "  'maybe',\n",
       "  'little',\n",
       "  'pricy',\n",
       "  'area',\n",
       "  'good',\n",
       "  'lot',\n",
       "  'good',\n",
       "  'place',\n",
       "  'eat',\n",
       "  'nearby',\n",
       "  'transport',\n",
       "  'link',\n",
       "  'great',\n",
       "  'muni',\n",
       "  'two',\n",
       "  'black',\n",
       "  'away',\n",
       "  'mission',\n",
       "  'street',\n",
       "  'take',\n",
       "  'straight',\n",
       "  'downtown',\n",
       "  'would',\n",
       "  'definitely',\n",
       "  'recommend',\n",
       "  'place',\n",
       "  'someone',\n",
       "  'looking',\n",
       "  'basic',\n",
       "  'last',\n",
       "  'minute',\n",
       "  'accommodation',\n",
       "  'good',\n",
       "  'location'],\n",
       " ['stayed',\n",
       "  'laykoons',\n",
       "  'apartment',\n",
       "  'week',\n",
       "  'really',\n",
       "  'enjoyed',\n",
       "  'time',\n",
       "  'apartment',\n",
       "  'much',\n",
       "  'larger',\n",
       "  'picture',\n",
       "  'show',\n",
       "  'full',\n",
       "  'kitchen',\n",
       "  'living',\n",
       "  'room',\n",
       "  'impeccably',\n",
       "  'clean',\n",
       "  'laykoon',\n",
       "  'also',\n",
       "  'took',\n",
       "  'time',\n",
       "  'help',\n",
       "  'question',\n",
       "  'regarding',\n",
       "  'stay',\n",
       "  'professional',\n",
       "  'great',\n",
       "  'stay',\n",
       "  'thanks'])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train_wl = [map(review_to_wordlist, X_train)]\n",
    "#X_test_wl = [map(review_to_wordlist, X_test)]\n",
    "\n",
    "exp_wl = [review_to_wordlist(comment) for comment in exp_eng_data.word2vec]\n",
    "cheap_wl = [review_to_wordlist(comment) for comment in cheap_eng_data.word2vec]\n",
    "exp_wl[3],cheap_wl[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121485, 40496, 121485, 40496)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(X_wl,y)\n",
    "len(X_train),len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 9240\n",
      "Review 1000 of 9240\n",
      "Review 2000 of 9240\n",
      "Review 3000 of 9240\n",
      "Review 4000 of 9240\n",
      "Review 5000 of 9240\n",
      "Review 6000 of 9240\n",
      "Review 7000 of 9240\n",
      "Review 8000 of 9240\n",
      "Review 9000 of 9240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.02678226,  0.03893098,  0.00807955, -0.03790541,  0.04673043,\n",
       "        0.00959679,  0.16254832,  0.04318785,  0.02441642,  0.01412766,\n",
       "       -0.0049756 , -0.04537656,  0.03605764, -0.11092427, -0.05177397,\n",
       "        0.08739338,  0.00954814, -0.10272437, -0.01943629, -0.03009699,\n",
       "       -0.02316828, -0.01461026, -0.01517702,  0.01000217, -0.01122252,\n",
       "       -0.07412529, -0.05463564, -0.06995891,  0.03898394, -0.09025746,\n",
       "        0.02778273, -0.05908651,  0.0217025 ,  0.04917948, -0.18023346,\n",
       "       -0.00972061, -0.08939122,  0.06911238,  0.01645757,  0.05939141,\n",
       "       -0.04112816, -0.07851529, -0.09523399,  0.06264875,  0.04230859,\n",
       "       -0.00774647,  0.01478744, -0.06059278,  0.07004013,  0.02467293], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_DataVecs = getAvgFeatureVecs(exp_wl, model, num_features )\n",
    "exp_DataVecs[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 42928\n",
      "Review 1000 of 42928\n",
      "Review 2000 of 42928\n",
      "Review 3000 of 42928\n",
      "Review 4000 of 42928\n",
      "Review 5000 of 42928\n",
      "Review 6000 of 42928\n",
      "Review 7000 of 42928\n",
      "Review 8000 of 42928\n",
      "Review 9000 of 42928\n",
      "Review 10000 of 42928\n",
      "Review 11000 of 42928\n",
      "Review 12000 of 42928\n",
      "Review 13000 of 42928\n",
      "Review 14000 of 42928\n",
      "Review 15000 of 42928\n",
      "Review 16000 of 42928\n",
      "Review 17000 of 42928\n",
      "Review 18000 of 42928\n",
      "Review 19000 of 42928\n",
      "Review 20000 of 42928\n",
      "Review 21000 of 42928\n",
      "Review 22000 of 42928\n",
      "Review 23000 of 42928\n",
      "Review 24000 of 42928\n",
      "Review 25000 of 42928\n",
      "Review 26000 of 42928\n",
      "Review 27000 of 42928\n",
      "Review 28000 of 42928\n",
      "Review 29000 of 42928\n",
      "Review 30000 of 42928\n",
      "Review 31000 of 42928\n",
      "Review 32000 of 42928\n",
      "Review 33000 of 42928\n",
      "Review 34000 of 42928\n",
      "Review 35000 of 42928\n",
      "Review 36000 of 42928\n",
      "Review 37000 of 42928\n",
      "Review 38000 of 42928\n",
      "Review 39000 of 42928\n",
      "Review 40000 of 42928\n",
      "Review 41000 of 42928\n",
      "Review 42000 of 42928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cheap_DataVecs = getAvgFeatureVecs(cheap_wl, model, num_features )\n",
    "len(cheap_DataVecs[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04755645, -0.00167838, -0.01962808, -0.06741405,  0.01089127,\n",
       "         0.06410567,  0.12480619,  0.09225535, -0.07114873,  0.01717472,\n",
       "        -0.0168408 , -0.04294909,  0.04872614, -0.04396426, -0.06518949,\n",
       "         0.02215939, -0.04208612, -0.11247621,  0.02784273,  0.02358133,\n",
       "        -0.02207324, -0.06871423, -0.04975123, -0.0015294 , -0.01553071,\n",
       "         0.02248274, -0.05397125, -0.03242316, -0.00498694, -0.06667902,\n",
       "         0.02439507, -0.00981731,  0.00234602,  0.01202132, -0.09368477,\n",
       "        -0.0121548 , -0.06120722,  0.01175749,  0.05998155,  0.0380748 ,\n",
       "        -0.05416548,  0.0123213 , -0.04799069,  0.08419929, -0.00048272,\n",
       "         0.0489191 ,  0.02218951, -0.04107046,  0.04497211,  0.0017595 ],\n",
       "       [ 0.0037099 ,  0.04275937, -0.01245425, -0.00937239,  0.02915253,\n",
       "         0.00746397,  0.06555413,  0.02137936,  0.05343761,  0.07152858,\n",
       "         0.03710501, -0.01553633,  0.04652159, -0.02799917,  0.05030333,\n",
       "         0.10235712, -0.01793932, -0.00562976, -0.05184243,  0.00259165,\n",
       "        -0.03605229, -0.0958545 ,  0.0354028 ,  0.03412328, -0.02035126,\n",
       "         0.05077409,  0.00172003, -0.04747277, -0.05221109, -0.08315009,\n",
       "         0.01418908, -0.0331843 ,  0.05015726,  0.03661967, -0.08056875,\n",
       "        -0.06406806, -0.1450558 ,  0.09817397, -0.03971381,  0.12705973,\n",
       "        -0.06365911, -0.07066869, -0.08084875,  0.01887588,  0.01169465,\n",
       "        -0.01483674, -0.00251257, -0.00608971,  0.12550001, -0.09364889]], dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_DataVecs[[12,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9240, 42928, 230, 1070, 1300)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_n = len(exp_eng_data)\n",
    "cheap_n=len(cheap_eng_data)\n",
    "exp_n_samples = int(1300*exp_n/(exp_n+cheap_n))\n",
    "cheap_n_samples = int(1300*cheap_n/(exp_n+cheap_n))+1\n",
    "exp_n, cheap_n,exp_n_samples, cheap_n_samples, exp_n_samples+cheap_n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_1300():\n",
    "    random_exp = np.random.randint(0,exp_n,exp_n_samples)\n",
    "    random_cheap=np.random.randint(0,cheap_n,cheap_n_samples)\n",
    "    X=np.concatenate((exp_DataVecs[random_exp],cheap_DataVecs[random_cheap]),axis=0)\n",
    "    #y=np.concatenate((exp_eng_data.price_tag[random_exp],cheap_eng_data.price_tag[random_cheap]),axis=0)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-f45cb14d221c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#y=np.concatenate((exp_eng_data.price_tag[random_exp],cheap_eng_data.price_tag[random_cheap]),axis=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#y=np.array(np.concatenate(([['exp']*exp_n_samples],[['cheap']*cheap_n_samples]),axis=0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexp_n_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cheap'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcheap_n_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "\n",
    "random_exp = np.random.randint(0,exp_n,3)\n",
    "random_cheap=np.random.randint(0,cheap_n,3)\n",
    "#X=np.concatenate(exp_DataVecs[random_exp],cheap_DataVecs[random_cheap])\n",
    "#y=np.concatenate((exp_eng_data.price_tag[random_exp],cheap_eng_data.price_tag[random_cheap]),axis=0)\n",
    "#y=np.array(np.concatenate(([['exp']*exp_n_samples],[['cheap']*cheap_n_samples]),axis=0))\n",
    "y=np.array(['exp']*exp_n_samples,['cheap']*cheap_n_samples)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['exp'], dtype=object), 9240)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(exp_eng_data.price_tag), len(exp_eng_data.price_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         exp\n",
       "2         exp\n",
       "4         exp\n",
       "5         exp\n",
       "6         exp\n",
       "7         exp\n",
       "8         exp\n",
       "9         exp\n",
       "10        exp\n",
       "11        exp\n",
       "12        exp\n",
       "13        exp\n",
       "14        exp\n",
       "15        exp\n",
       "16        exp\n",
       "17        exp\n",
       "18        exp\n",
       "19        exp\n",
       "20        exp\n",
       "21        exp\n",
       "22        exp\n",
       "23        exp\n",
       "24        exp\n",
       "25        exp\n",
       "26        exp\n",
       "28        exp\n",
       "29        exp\n",
       "679       exp\n",
       "680       exp\n",
       "1019      exp\n",
       "         ... \n",
       "169607    exp\n",
       "169608    exp\n",
       "169609    exp\n",
       "169610    exp\n",
       "169611    exp\n",
       "169612    exp\n",
       "169613    exp\n",
       "169614    exp\n",
       "169615    exp\n",
       "169616    exp\n",
       "169617    exp\n",
       "169618    exp\n",
       "169619    exp\n",
       "169620    exp\n",
       "169621    exp\n",
       "169622    exp\n",
       "169623    exp\n",
       "169624    exp\n",
       "169625    exp\n",
       "169626    exp\n",
       "169627    exp\n",
       "169628    exp\n",
       "169629    exp\n",
       "169707    exp\n",
       "169708    exp\n",
       "169709    exp\n",
       "169710    exp\n",
       "169711    exp\n",
       "169712    exp\n",
       "169713    exp\n",
       "Name: price_tag, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_eng_data.price_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9166, 2360, 8793]), array([39401, 11611,  2376]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_exp, random_cheap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['exp', 'exp', 'exp'],\n",
       "       ['cheap', 'cheap', 'cheap']], \n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9240"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exp_eng_data.price_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2682, 4682, 8383]), array([22221,   181,   356]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_exp, random_cheap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00267449,  0.0134945 ,  0.01952867, ..., -0.02968097,\n",
       "        -0.05948286, -0.04449563],\n",
       "       [-0.02713343,  0.02143814, -0.0038173 , ..., -0.00012941,\n",
       "         0.00395378, -0.01223448],\n",
       "       [ 0.00132237,  0.00630784, -0.0009618 , ...,  0.02306151,\n",
       "         0.05571912,  0.04475218],\n",
       "       [-0.01960815,  0.01942927, -0.00918256, ...,  0.02507635,\n",
       "        -0.0099659 ,  0.03595438],\n",
       "       [-0.00647312,  0.02243038, -0.00465661, ..., -0.0031122 ,\n",
       "        -0.01165516,  0.0241308 ],\n",
       "       [-0.00434918,  0.02403334, -0.01766017, ...,  0.00776346,\n",
       "         0.00466764,  0.00039289]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((exp_DataVecs[random_exp],cheap_DataVecs[random_cheap]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train=sample_1300()\n",
    "X_test, y_test = sample_1300()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, ..., nan, nan, nan], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03252693,  0.01478382,  0.00282546, ..., -0.10158304,\n",
       "         0.09401321,  0.01120427],\n",
       "       [ 0.05036823,  0.03773965,  0.02604673, ..., -0.001945  ,\n",
       "         0.06997605,  0.0066389 ],\n",
       "       [ 0.04656626, -0.02710426,  0.0234201 , ...,  0.03605892,\n",
       "         0.15647212, -0.00844479],\n",
       "       ..., \n",
       "       [ 0.01199672, -0.02221547, -0.00865069, ...,  0.00790429,\n",
       "         0.05476882,  0.00096489],\n",
       "       [ 0.00805571,  0.00509227, -0.0515242 , ..., -0.06410341,\n",
       "         0.07748736,  0.01586029],\n",
       "       [-0.00146464, -0.01314441, -0.01517062, ..., -0.01791876,\n",
       "         0.01314195,  0.02509518]], dtype=float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Datavecs=np.concatenate((exp_DataVecs,cheap_DataVecs),axis=0)\n",
    "X_Datavecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1           exp\n",
       "2           exp\n",
       "4           exp\n",
       "5           exp\n",
       "6           exp\n",
       "7           exp\n",
       "8           exp\n",
       "9           exp\n",
       "10          exp\n",
       "11          exp\n",
       "12          exp\n",
       "13          exp\n",
       "14          exp\n",
       "15          exp\n",
       "16          exp\n",
       "17          exp\n",
       "18          exp\n",
       "19          exp\n",
       "20          exp\n",
       "21          exp\n",
       "22          exp\n",
       "23          exp\n",
       "24          exp\n",
       "25          exp\n",
       "26          exp\n",
       "28          exp\n",
       "29          exp\n",
       "30        cheap\n",
       "31        cheap\n",
       "32        cheap\n",
       "          ...  \n",
       "169611      exp\n",
       "169612      exp\n",
       "169613      exp\n",
       "169614      exp\n",
       "169615      exp\n",
       "169616      exp\n",
       "169617      exp\n",
       "169618      exp\n",
       "169619      exp\n",
       "169620      exp\n",
       "169621      exp\n",
       "169622      exp\n",
       "169623      exp\n",
       "169624      exp\n",
       "169625      exp\n",
       "169626      exp\n",
       "169627      exp\n",
       "169628      exp\n",
       "169629      exp\n",
       "169707      exp\n",
       "169708      exp\n",
       "169709      exp\n",
       "169710      exp\n",
       "169711      exp\n",
       "169712      exp\n",
       "169713      exp\n",
       "169726    cheap\n",
       "169727    cheap\n",
       "169729    cheap\n",
       "169730    cheap\n",
       "Name: price_tag, dtype: object"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=eng_data[(eng_data.price_tag!='neutral')].price_tag\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39126, 13042, 39126, 13042)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(X_Datavecs,y)\n",
    "len(X_train),len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READY TO ML!!!\n"
     ]
    }
   ],
   "source": [
    "print('READY TO ML!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-131a92a7e7b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrandomforest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrandomforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "randomforest = RandomForestClassifier( n_estimators = 10)\n",
    "randomforest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = randomforest.predict(testDataVecs[:1300])\n",
    "y_test_sample = y_test[:1300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.684615384615\n",
      "Precision: 0.332056002788\n",
      "Recall: 0.295656724228\n",
      "F1: 0.28042475695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Applications/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", sum(y_predict==y_test_sample)/len(y_test_sample))\n",
    "print(\"Precision:\", precision_score(y_predict,y_test_sample, average=\"macro\") )\n",
    "print(\"Recall:\", recall_score(y_predict,y_test_sample, average=\"macro\") ) \n",
    "print(\"F1:\", f1_score(y_predict,y_test_sample, average=\"macro\") ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.931562857417\n",
      "Recall: 0.677692307692\n",
      "F1: 0.780546923864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Applications/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#weighted metrics, since groups are not balanced\n",
    "\n",
    "print(\"Precision:\", precision_score(y_predict,y_test_sample, average=\"weighted\") )\n",
    "print(\"Recall:\", recall_score(y_predict,y_test_sample, average=\"weighted\") )\n",
    "print(\"F1:\", f1_score(y_predict,y_test_sample, average=\"weighted\") )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: Actual, Columns: Predicted\n",
      "cheap neutral exp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  5,  17,   4],\n",
       "       [328, 885,  61],\n",
       "       [  0,   0,   0]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Rows: Actual, Columns: Predicted\")\n",
    "print('cheap', 'neutral', 'exp')\n",
    "confusion_matrix(y_predict,y_test_sample, labels = ['cheap', 'neutral', 'exp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-6072c9a20800>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Call fit method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainDataVecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    585\u001b[0m         self.feature_count_ = np.zeros((n_effective_classes, n_features),\n\u001b[1;32m    586\u001b[0m                                        dtype=np.float64)\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_class_log_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_prior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_prior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input X must be non-negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input X must be non-negative"
     ]
    }
   ],
   "source": [
    "#multinomial NaiveBayes\n",
    "\n",
    "clf = MultinomialNB()\n",
    "# Call fit method\n",
    "clf.fit(trainDataVecs[:100],y_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-204-7c2ea4533a36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msvm_clf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msvm_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainDataVecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msvm_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestDataVecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \"\"\"\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \"\"\"\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseSVC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'support_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "svm_clf=SVC(C=1, gamma=0.1)\n",
    "svm_clf.fit(trainDataVecs[:1300],y_train[:1300])\n",
    "svm_clf.score(testDataVecs[:10000], y_test[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56       cheap\n",
       "90       cheap\n",
       "889    neutral\n",
       "75       cheap\n",
       "Name: price_tag, dtype: object"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[[56,90,889,75]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
